{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä Sales Dataset EDA - Ph√¢n T√≠ch D·ªØ Li·ªáu B√°n H√†ng\n",
        "\n",
        "## üéØ M·ª•c Ti√™u\n",
        "Ph√¢n t√≠ch kh√°m ph√° d·ªØ li·ªáu b√°n h√†ng ƒë·ªÉ hi·ªÉu:\n",
        "- Xu h∆∞·ªõng b√°n h√†ng theo th·ªùi gian\n",
        "- Ph√¢n t√≠ch theo s·∫£n ph·∫©m, khu v·ª±c, kh√°ch h√†ng\n",
        "- Seasonal patterns v√† trends\n",
        "- Customer behavior analysis\n",
        "\n",
        "## üìã Dataset Overview\n",
        "- **Ngu·ªìn**: Synthetic Sales Data\n",
        "- **Th·ªùi gian**: 2 nƒÉm (2022-2023)\n",
        "- **Features**: Date, Product, Category, Region, Customer, Sales, Quantity, Price\n",
        "- **M·ª•c ti√™u**: Time series analysis, seasonal patterns, customer segmentation\n",
        "\n",
        "## üîç K·ªπ Thu·∫≠t S·∫Ω S·ª≠ D·ª•ng\n",
        "- Time series analysis\n",
        "- Seasonal decomposition\n",
        "- Customer segmentation\n",
        "- Product performance analysis\n",
        "- Geographic analysis\n",
        "- Trend analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# C√†i ƒë·∫∑t style cho plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ ƒê√£ import th√†nh c√¥ng t·∫•t c·∫£ th∆∞ vi·ªán!\")\n",
        "print(\"üìä S·∫µn s√†ng b·∫Øt ƒë·∫ßu ph√¢n t√≠ch Sales Dataset!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 1: T·∫°o Synthetic Sales Dataset\n",
        "\n",
        "T·∫°o dataset b√°n h√†ng t·ªïng h·ª£p v·ªõi c√°c ƒë·∫∑c ƒëi·ªÉm th·ª±c t·∫ø:\n",
        "- D·ªØ li·ªáu 2 nƒÉm (2022-2023)\n",
        "- 5 s·∫£n ph·∫©m ch√≠nh v·ªõi 3 categories\n",
        "- 4 khu v·ª±c b√°n h√†ng\n",
        "- 1000+ kh√°ch h√†ng\n",
        "- Seasonal patterns v√† trends\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m start_date = \u001b[33m'\u001b[39m\u001b[33m2022-01-01\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m end_date = \u001b[33m'\u001b[39m\u001b[33m2023-12-31\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m date_range = \u001b[43mpd\u001b[49m.date_range(start=start_date, end=end_date, freq=\u001b[33m'\u001b[39m\u001b[33mD\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# S·∫£n ph·∫©m v√† categories\u001b[39;00m\n\u001b[32m     11\u001b[39m products = {\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLaptop Gaming\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mElectronics\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33miPhone 14\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mElectronics\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mNike T-Shirt\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mFashion\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     22\u001b[39m }\n",
            "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# T·∫°o synthetic sales dataset\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Th√¥ng tin c∆° b·∫£n\n",
        "start_date = '2022-01-01'\n",
        "end_date = '2023-12-31'\n",
        "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "\n",
        "# S·∫£n ph·∫©m v√† categories\n",
        "products = {\n",
        "    'Laptop Gaming': 'Electronics',\n",
        "    'iPhone 14': 'Electronics', \n",
        "    'Nike Air Max': 'Fashion',\n",
        "    'Adidas Ultraboost': 'Fashion',\n",
        "    'MacBook Pro': 'Electronics',\n",
        "    'Samsung Galaxy': 'Electronics',\n",
        "    'Levi\\'s Jeans': 'Fashion',\n",
        "    'Zara Jacket': 'Fashion',\n",
        "    'iPad Air': 'Electronics',\n",
        "    'Nike T-Shirt': 'Fashion'\n",
        "}\n",
        "\n",
        "# Khu v·ª±c\n",
        "regions = ['North', 'South', 'East', 'West']\n",
        "\n",
        "# T·∫°o d·ªØ li·ªáu\n",
        "sales_data = []\n",
        "\n",
        "for date in date_range:\n",
        "    # S·ªë l∆∞·ª£ng giao d·ªãch trong ng√†y (c√≥ seasonal pattern)\n",
        "    day_of_year = date.timetuple().tm_yday\n",
        "    seasonal_factor = 1 + 0.3 * np.sin(2 * np.pi * day_of_year / 365)  # Seasonal pattern\n",
        "    weekend_factor = 0.7 if date.weekday() >= 5 else 1.0  # Weekend effect\n",
        "    holiday_factor = 1.5 if date.month in [11, 12] else 1.0  # Holiday season\n",
        "    \n",
        "    num_transactions = int(np.random.poisson(50 * seasonal_factor * weekend_factor * holiday_factor))\n",
        "    \n",
        "    for _ in range(num_transactions):\n",
        "        product = np.random.choice(list(products.keys()))\n",
        "        category = products[product]\n",
        "        region = np.random.choice(regions)\n",
        "        customer_id = f\"CUST_{np.random.randint(1000, 9999)}\"\n",
        "        \n",
        "        # Gi√° s·∫£n ph·∫©m (c√≥ variation theo th·ªùi gian)\n",
        "        base_prices = {\n",
        "            'Laptop Gaming': 1200, 'iPhone 14': 800, 'Nike Air Max': 120,\n",
        "            'Adidas Ultraboost': 150, 'MacBook Pro': 2000, 'Samsung Galaxy': 600,\n",
        "            'Levi\\'s Jeans': 80, 'Zara Jacket': 120, 'iPad Air': 500, 'Nike T-Shirt': 30\n",
        "        }\n",
        "        \n",
        "        base_price = base_prices[product]\n",
        "        price_variation = np.random.normal(1, 0.1)  # 10% variation\n",
        "        price = base_price * price_variation\n",
        "        \n",
        "        # S·ªë l∆∞·ª£ng (th∆∞·ªùng 1-3 items)\n",
        "        quantity = np.random.choice([1, 2, 3], p=[0.7, 0.2, 0.1])\n",
        "        \n",
        "        # Total sales\n",
        "        sales = price * quantity\n",
        "        \n",
        "        # Discount factor (10% chance of discount)\n",
        "        if np.random.random() < 0.1:\n",
        "            discount = np.random.uniform(0.05, 0.25)\n",
        "            sales *= (1 - discount)\n",
        "        \n",
        "        sales_data.append({\n",
        "            'Date': date,\n",
        "            'Product': product,\n",
        "            'Category': category,\n",
        "            'Region': region,\n",
        "            'Customer_ID': customer_id,\n",
        "            'Price': round(price, 2),\n",
        "            'Quantity': quantity,\n",
        "            'Sales': round(sales, 2),\n",
        "            'Year': date.year,\n",
        "            'Month': date.month,\n",
        "            'Day': date.day,\n",
        "            'Weekday': date.weekday(),\n",
        "            'Quarter': date.quarter\n",
        "        })\n",
        "\n",
        "# T·∫°o DataFrame\n",
        "df = pd.DataFrame(sales_data)\n",
        "\n",
        "print(f\"‚úÖ ƒê√£ t·∫°o th√†nh c√¥ng Sales Dataset!\")\n",
        "print(f\"üìä K√≠ch th∆∞·ªõc dataset: {df.shape}\")\n",
        "print(f\"üìÖ Th·ªùi gian: {df['Date'].min()} ƒë·∫øn {df['Date'].max()}\")\n",
        "print(f\"üí∞ T·ªïng doanh thu: ${df['Sales'].sum():,.2f}\")\n",
        "print(f\"üõçÔ∏è T·ªïng s·ªë giao d·ªãch: {len(df):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 2: Data Loading & Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ki·ªÉm tra th√¥ng tin c∆° b·∫£n v·ªÅ dataset\n",
        "print(\"üîç TH√îNG TIN C∆† B·∫¢N V·ªÄ DATASET\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìä Shape: {df.shape}\")\n",
        "print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(f\"üìÖ Date range: {df['Date'].min()} ƒë·∫øn {df['Date'].max()}\")\n",
        "print(f\"üìà Total days: {(df['Date'].max() - df['Date'].min()).days + 1}\")\n",
        "\n",
        "print(\"\\nüìã COLUMNS INFO:\")\n",
        "print(\"=\" * 30)\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nüî¢ DATA TYPES:\")\n",
        "print(\"=\" * 20)\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nüìä SAMPLE DATA (5 rows ƒë·∫ßu):\")\n",
        "print(\"=\" * 35)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ki·ªÉm tra missing values\n",
        "print(\"üîç MISSING VALUES ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percent = (missing_data / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_data,\n",
        "    'Missing Percentage': missing_percent\n",
        "})\n",
        "\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "if missing_df['Missing Count'].sum() == 0:\n",
        "    print(\"‚úÖ Kh√¥ng c√≥ missing values trong dataset!\")\n",
        "\n",
        "# Ki·ªÉm tra duplicate rows\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"\\nüîÑ Duplicate rows: {duplicates}\")\n",
        "\n",
        "# Ki·ªÉm tra unique values cho categorical columns\n",
        "print(\"\\nüìä UNIQUE VALUES:\")\n",
        "print(\"=\" * 25)\n",
        "categorical_cols = ['Product', 'Category', 'Region', 'Customer_ID']\n",
        "for col in categorical_cols:\n",
        "    unique_count = df[col].nunique()\n",
        "    print(f\"{col}: {unique_count} unique values\")\n",
        "    \n",
        "    if col in ['Product', 'Category', 'Region']:\n",
        "        print(f\"  Values: {list(df[col].unique())}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 3: Data Profiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary cho numerical columns\n",
        "print(\"üìä STATISTICAL SUMMARY\")\n",
        "print(\"=\" * 30)\n",
        "numerical_cols = ['Price', 'Quantity', 'Sales']\n",
        "print(df[numerical_cols].describe().round(2))\n",
        "\n",
        "# Th√™m m·ªôt s·ªë th·ªëng k√™ b·ªï sung\n",
        "print(\"\\nüìà ADDITIONAL STATISTICS\")\n",
        "print(\"=\" * 35)\n",
        "for col in numerical_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Mean: ${df[col].mean():.2f}\")\n",
        "    print(f\"  Median: ${df[col].median():.2f}\")\n",
        "    print(f\"  Std: ${df[col].std():.2f}\")\n",
        "    print(f\"  Min: ${df[col].min():.2f}\")\n",
        "    print(f\"  Max: ${df[col].max():.2f}\")\n",
        "    print(f\"  Skewness: {df[col].skew():.3f}\")\n",
        "    print(f\"  Kurtosis: {df[col].kurtosis():.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ph√¢n t√≠ch categorical features\n",
        "print(\"üìä CATEGORICAL FEATURES ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Product analysis\n",
        "print(\"\\nüõçÔ∏è PRODUCT ANALYSIS:\")\n",
        "print(\"-\" * 25)\n",
        "product_stats = df.groupby('Product').agg({\n",
        "    'Sales': ['count', 'sum', 'mean'],\n",
        "    'Quantity': 'sum',\n",
        "    'Price': 'mean'\n",
        "}).round(2)\n",
        "product_stats.columns = ['Transactions', 'Total_Sales', 'Avg_Sales', 'Total_Quantity', 'Avg_Price']\n",
        "product_stats = product_stats.sort_values('Total_Sales', ascending=False)\n",
        "print(product_stats)\n",
        "\n",
        "# Category analysis\n",
        "print(\"\\nüìÇ CATEGORY ANALYSIS:\")\n",
        "print(\"-\" * 25)\n",
        "category_stats = df.groupby('Category').agg({\n",
        "    'Sales': ['count', 'sum', 'mean'],\n",
        "    'Quantity': 'sum',\n",
        "    'Price': 'mean'\n",
        "}).round(2)\n",
        "category_stats.columns = ['Transactions', 'Total_Sales', 'Avg_Sales', 'Total_Quantity', 'Avg_Price']\n",
        "category_stats = category_stats.sort_values('Total_Sales', ascending=False)\n",
        "print(category_stats)\n",
        "\n",
        "# Region analysis\n",
        "print(\"\\nüåç REGION ANALYSIS:\")\n",
        "print(\"-\" * 20)\n",
        "region_stats = df.groupby('Region').agg({\n",
        "    'Sales': ['count', 'sum', 'mean'],\n",
        "    'Quantity': 'sum',\n",
        "    'Price': 'mean'\n",
        "}).round(2)\n",
        "region_stats.columns = ['Transactions', 'Total_Sales', 'Avg_Sales', 'Total_Quantity', 'Avg_Price']\n",
        "region_stats = region_stats.sort_values('Total_Sales', ascending=False)\n",
        "print(region_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 4: Missing Value Analysis\n",
        "\n",
        "V√¨ dataset n√†y l√† synthetic data n√™n kh√¥ng c√≥ missing values, nh∆∞ng ch√∫ng ta s·∫Ω ki·ªÉm tra v√† t·∫°o visualization ƒë·ªÉ hi·ªÉu pattern.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing value visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Missing value heatmap\n",
        "missing_data = df.isnull().sum()\n",
        "if missing_data.sum() > 0:\n",
        "    sns.heatmap(df.isnull(), yticklabels=False, cbar=True, cmap='viridis', ax=axes[0])\n",
        "    axes[0].set_title('Missing Values Heatmap')\n",
        "else:\n",
        "    axes[0].text(0.5, 0.5, '‚úÖ No Missing Values', ha='center', va='center', \n",
        "                transform=axes[0].transAxes, fontsize=16, color='green')\n",
        "    axes[0].set_title('Missing Values Status')\n",
        "\n",
        "# Data completeness\n",
        "completeness = (1 - missing_data / len(df)) * 100\n",
        "bars = axes[1].bar(range(len(completeness)), completeness.values, color='lightgreen')\n",
        "axes[1].set_title('Data Completeness by Column')\n",
        "axes[1].set_xlabel('Columns')\n",
        "axes[1].set_ylabel('Completeness (%)')\n",
        "axes[1].set_xticks(range(len(completeness)))\n",
        "axes[1].set_xticklabels(completeness.index, rotation=45)\n",
        "axes[1].set_ylim(0, 105)\n",
        "\n",
        "# Add percentage labels on bars\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                f'{height:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Dataset ho√†n to√†n clean - kh√¥ng c√≥ missing values!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 5: Univariate Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Univariate Analysis - Numerical Features\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "numerical_cols = ['Price', 'Quantity', 'Sales']\n",
        "\n",
        "# Histograms\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    axes[i].hist(df[col], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    axes[i].set_title(f'Distribution of {col}')\n",
        "    axes[i].set_xlabel(col)\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "# Box plots\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    axes[i+3].boxplot(df[col], patch_artist=True, \n",
        "                     boxprops=dict(facecolor='lightcoral', alpha=0.7))\n",
        "    axes[i+3].set_title(f'Box Plot of {col}')\n",
        "    axes[i+3].set_ylabel(col)\n",
        "    axes[i+3].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical insights\n",
        "print(\"üìä UNIVARIATE ANALYSIS INSIGHTS\")\n",
        "print(\"=\" * 40)\n",
        "for col in numerical_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Distribution: {'Right-skewed' if df[col].skew() > 0.5 else 'Left-skewed' if df[col].skew() < -0.5 else 'Approximately normal'}\")\n",
        "    print(f\"  Outliers: {len(df[(df[col] < df[col].quantile(0.25) - 1.5*(df[col].quantile(0.75) - df[col].quantile(0.25))) | (df[col] > df[col].quantile(0.75) + 1.5*(df[col].quantile(0.75) - df[col].quantile(0.25)))])} values\")\n",
        "    print(f\"  Range: ${df[col].min():.2f} - ${df[col].max():.2f}\")\n",
        "    print(f\"  IQR: ${df[col].quantile(0.75) - df[col].quantile(0.25):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Univariate Analysis - Categorical Features\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Product distribution\n",
        "product_counts = df['Product'].value_counts()\n",
        "axes[0,0].bar(range(len(product_counts)), product_counts.values, color='lightblue')\n",
        "axes[0,0].set_title('Product Distribution')\n",
        "axes[0,0].set_xlabel('Products')\n",
        "axes[0,0].set_ylabel('Number of Transactions')\n",
        "axes[0,0].set_xticks(range(len(product_counts)))\n",
        "axes[0,0].set_xticklabels(product_counts.index, rotation=45, ha='right')\n",
        "\n",
        "# Category distribution\n",
        "category_counts = df['Category'].value_counts()\n",
        "axes[0,1].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%', \n",
        "              colors=['lightcoral', 'lightgreen', 'lightblue'])\n",
        "axes[0,1].set_title('Category Distribution')\n",
        "\n",
        "# Region distribution\n",
        "region_counts = df['Region'].value_counts()\n",
        "axes[1,0].bar(range(len(region_counts)), region_counts.values, color='lightgreen')\n",
        "axes[1,0].set_title('Region Distribution')\n",
        "axes[1,0].set_xlabel('Regions')\n",
        "axes[1,0].set_ylabel('Number of Transactions')\n",
        "axes[1,0].set_xticks(range(len(region_counts)))\n",
        "axes[1,0].set_xticklabels(region_counts.index)\n",
        "\n",
        "# Weekday distribution\n",
        "weekday_counts = df['Weekday'].value_counts().sort_index()\n",
        "weekday_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "axes[1,1].bar(range(len(weekday_counts)), weekday_counts.values, color='lightcoral')\n",
        "axes[1,1].set_title('Weekday Distribution')\n",
        "axes[1,1].set_xlabel('Day of Week')\n",
        "axes[1,1].set_ylabel('Number of Transactions')\n",
        "axes[1,1].set_xticks(range(len(weekday_counts)))\n",
        "axes[1,1].set_xticklabels(weekday_names)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Categorical insights\n",
        "print(\"\\nüìä CATEGORICAL ANALYSIS INSIGHTS\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Most popular product: {product_counts.index[0]} ({product_counts.iloc[0]} transactions)\")\n",
        "print(f\"Most popular category: {category_counts.index[0]} ({category_counts.iloc[0]} transactions)\")\n",
        "print(f\"Most active region: {region_counts.index[0]} ({region_counts.iloc[0]} transactions)\")\n",
        "print(f\"Busiest day: {weekday_names[weekday_counts.index[0]]} ({weekday_counts.iloc[0]} transactions)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 6: Bivariate Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Analysis\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Correlation matrix\n",
        "numerical_cols = ['Price', 'Quantity', 'Sales']\n",
        "correlation_matrix = df[numerical_cols].corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, ax=axes[0])\n",
        "axes[0].set_title('Correlation Matrix - Numerical Features')\n",
        "\n",
        "# Scatter plots\n",
        "axes[1].scatter(df['Price'], df['Sales'], alpha=0.5, color='blue')\n",
        "axes[1].set_xlabel('Price')\n",
        "axes[1].set_ylabel('Sales')\n",
        "axes[1].set_title('Price vs Sales')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation insights\n",
        "print(\"üìä CORRELATION ANALYSIS\")\n",
        "print(\"=\" * 30)\n",
        "print(\"Correlation coefficients:\")\n",
        "for i in range(len(numerical_cols)):\n",
        "    for j in range(i+1, len(numerical_cols)):\n",
        "        corr = correlation_matrix.iloc[i, j]\n",
        "        print(f\"  {numerical_cols[i]} vs {numerical_cols[j]}: {corr:.3f}\")\n",
        "        \n",
        "print(f\"\\nStrongest correlation: {correlation_matrix.abs().stack().nlargest(2).iloc[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorical vs Numerical Analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Sales by Category\n",
        "sns.boxplot(data=df, x='Category', y='Sales', ax=axes[0,0])\n",
        "axes[0,0].set_title('Sales Distribution by Category')\n",
        "axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Sales by Region\n",
        "sns.boxplot(data=df, x='Region', y='Sales', ax=axes[0,1])\n",
        "axes[0,1].set_title('Sales Distribution by Region')\n",
        "\n",
        "# Sales by Weekday\n",
        "sns.boxplot(data=df, x='Weekday', y='Sales', ax=axes[1,0])\n",
        "axes[1,0].set_title('Sales Distribution by Weekday')\n",
        "weekday_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "axes[1,0].set_xticklabels(weekday_names)\n",
        "\n",
        "# Average Sales by Product\n",
        "product_sales = df.groupby('Product')['Sales'].mean().sort_values(ascending=False)\n",
        "axes[1,1].bar(range(len(product_sales)), product_sales.values, color='lightcoral')\n",
        "axes[1,1].set_title('Average Sales by Product')\n",
        "axes[1,1].set_xlabel('Products')\n",
        "axes[1,1].set_ylabel('Average Sales ($)')\n",
        "axes[1,1].set_xticks(range(len(product_sales)))\n",
        "axes[1,1].set_xticklabels(product_sales.index, rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bivariate insights\n",
        "print(\"\\nüìä BIVARIATE ANALYSIS INSIGHTS\")\n",
        "print(\"=\" * 40)\n",
        "print(\"Average Sales by Category:\")\n",
        "for category in df['Category'].unique():\n",
        "    avg_sales = df[df['Category'] == category]['Sales'].mean()\n",
        "    print(f\"  {category}: ${avg_sales:.2f}\")\n",
        "\n",
        "print(\"\\nAverage Sales by Region:\")\n",
        "for region in df['Region'].unique():\n",
        "    avg_sales = df[df['Region'] == region]['Sales'].mean()\n",
        "    print(f\"  {region}: ${avg_sales:.2f}\")\n",
        "\n",
        "print(\"\\nAverage Sales by Weekday:\")\n",
        "for i, day in enumerate(weekday_names):\n",
        "    avg_sales = df[df['Weekday'] == i]['Sales'].mean()\n",
        "    print(f\"  {day}: ${avg_sales:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 7: Time Series Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time Series Analysis\n",
        "# T·∫°o daily sales data\n",
        "daily_sales = df.groupby('Date').agg({\n",
        "    'Sales': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'Customer_ID': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "daily_sales.columns = ['Date', 'Daily_Sales', 'Daily_Quantity', 'Unique_Customers']\n",
        "\n",
        "# T·∫°o monthly sales data\n",
        "monthly_sales = df.groupby(['Year', 'Month']).agg({\n",
        "    'Sales': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'Customer_ID': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "monthly_sales['Date'] = pd.to_datetime(monthly_sales[['Year', 'Month']].assign(day=1))\n",
        "monthly_sales.columns = ['Year', 'Month', 'Monthly_Sales', 'Monthly_Quantity', 'Unique_Customers', 'Date']\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Daily sales trend\n",
        "axes[0,0].plot(daily_sales['Date'], daily_sales['Daily_Sales'], color='blue', alpha=0.7)\n",
        "axes[0,0].set_title('Daily Sales Trend')\n",
        "axes[0,0].set_xlabel('Date')\n",
        "axes[0,0].set_ylabel('Daily Sales ($)')\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Monthly sales trend\n",
        "axes[0,1].plot(monthly_sales['Date'], monthly_sales['Monthly_Sales'], \n",
        "               marker='o', color='red', linewidth=2)\n",
        "axes[0,1].set_title('Monthly Sales Trend')\n",
        "axes[0,1].set_xlabel('Date')\n",
        "axes[0,1].set_ylabel('Monthly Sales ($)')\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "# Sales by month (seasonal pattern)\n",
        "monthly_avg = df.groupby('Month')['Sales'].mean()\n",
        "axes[1,0].bar(monthly_avg.index, monthly_avg.values, color='lightgreen')\n",
        "axes[1,0].set_title('Average Sales by Month (Seasonal Pattern)')\n",
        "axes[1,0].set_xlabel('Month')\n",
        "axes[1,0].set_ylabel('Average Sales ($)')\n",
        "axes[1,0].set_xticks(range(1, 13))\n",
        "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "axes[1,0].set_xticklabels(month_names)\n",
        "\n",
        "# Sales by quarter\n",
        "quarterly_sales = df.groupby('Quarter')['Sales'].sum()\n",
        "axes[1,1].pie(quarterly_sales.values, labels=[f'Q{i}' for i in quarterly_sales.index], \n",
        "              autopct='%1.1f%%', colors=['lightcoral', 'lightblue', 'lightgreen', 'lightyellow'])\n",
        "axes[1,1].set_title('Sales Distribution by Quarter')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Time series insights\n",
        "print(\"üìä TIME SERIES ANALYSIS INSIGHTS\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Highest daily sales: ${daily_sales['Daily_Sales'].max():,.2f} on {daily_sales.loc[daily_sales['Daily_Sales'].idxmax(), 'Date'].strftime('%Y-%m-%d')}\")\n",
        "print(f\"Lowest daily sales: ${daily_sales['Daily_Sales'].min():,.2f} on {daily_sales.loc[daily_sales['Daily_Sales'].idxmin(), 'Date'].strftime('%Y-%m-%d')}\")\n",
        "print(f\"Average daily sales: ${daily_sales['Daily_Sales'].mean():,.2f}\")\n",
        "print(f\"Best performing month: {month_names[monthly_avg.idxmax()-1]} (${monthly_avg.max():,.2f})\")\n",
        "print(f\"Worst performing month: {month_names[monthly_avg.idxmin()-1]} (${monthly_avg.min():,.2f})\")\n",
        "print(f\"Best performing quarter: Q{quarterly_sales.idxmax()} (${quarterly_sales.max():,.2f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 8: Multivariate Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced Multivariate Analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "\n",
        "# Sales by Category and Region (Heatmap)\n",
        "category_region_sales = df.groupby(['Category', 'Region'])['Sales'].sum().unstack()\n",
        "sns.heatmap(category_region_sales, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[0,0])\n",
        "axes[0,0].set_title('Sales Heatmap: Category vs Region')\n",
        "\n",
        "# Sales by Product and Month\n",
        "product_month_sales = df.groupby(['Product', 'Month'])['Sales'].sum().unstack()\n",
        "sns.heatmap(product_month_sales, annot=False, cmap='viridis', ax=axes[0,1])\n",
        "axes[0,1].set_title('Sales Heatmap: Product vs Month')\n",
        "axes[0,1].set_xticklabels(month_names, rotation=45)\n",
        "\n",
        "# Average Sales by Category and Weekday\n",
        "category_weekday_sales = df.groupby(['Category', 'Weekday'])['Sales'].mean().unstack()\n",
        "sns.heatmap(category_weekday_sales, annot=True, fmt='.0f', cmap='Blues', ax=axes[1,0])\n",
        "axes[1,0].set_title('Average Sales: Category vs Weekday')\n",
        "axes[1,0].set_xticklabels(weekday_names)\n",
        "\n",
        "# Sales distribution by Region and Category\n",
        "sns.violinplot(data=df, x='Region', y='Sales', hue='Category', ax=axes[1,1])\n",
        "axes[1,1].set_title('Sales Distribution: Region vs Category')\n",
        "axes[1,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Multivariate insights\n",
        "print(\"üìä MULTIVARIATE ANALYSIS INSIGHTS\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Top performing combinations\n",
        "print(\"\\nüèÜ TOP PERFORMING COMBINATIONS:\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "# Category-Region combination\n",
        "cat_reg_comb = df.groupby(['Category', 'Region'])['Sales'].sum().sort_values(ascending=False)\n",
        "print(\"Top Category-Region combinations:\")\n",
        "for i, (combo, sales) in enumerate(cat_reg_comb.head(3).items()):\n",
        "    print(f\"  {i+1}. {combo[0]} in {combo[1]}: ${sales:,.2f}\")\n",
        "\n",
        "# Product-Month combination\n",
        "prod_month_comb = df.groupby(['Product', 'Month'])['Sales'].sum().sort_values(ascending=False)\n",
        "print(\"\\nTop Product-Month combinations:\")\n",
        "for i, (combo, sales) in enumerate(prod_month_comb.head(3).items()):\n",
        "    print(f\"  {i+1}. {combo[0]} in {month_names[combo[1]-1]}: ${sales:,.2f}\")\n",
        "\n",
        "# Category-Weekday combination\n",
        "cat_weekday_comb = df.groupby(['Category', 'Weekday'])['Sales'].mean().sort_values(ascending=False)\n",
        "print(\"\\nTop Category-Weekday combinations (by average):\")\n",
        "for i, (combo, sales) in enumerate(cat_weekday_comb.head(3).items()):\n",
        "    print(f\"  {i+1}. {combo[0]} on {weekday_names[combo[1]]}: ${sales:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Customer Analysis\n",
        "print(\"üë• CUSTOMER ANALYSIS\")\n",
        "print(\"=\" * 25)\n",
        "\n",
        "# Top customers by total sales\n",
        "top_customers = df.groupby('Customer_ID').agg({\n",
        "    'Sales': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'Date': 'count'\n",
        "}).sort_values('Sales', ascending=False)\n",
        "\n",
        "top_customers.columns = ['Total_Sales', 'Total_Quantity', 'Transaction_Count']\n",
        "print(\"Top 10 customers by total sales:\")\n",
        "print(top_customers.head(10).round(2))\n",
        "\n",
        "# Customer segments based on purchase behavior\n",
        "customer_stats = df.groupby('Customer_ID').agg({\n",
        "    'Sales': ['sum', 'mean', 'count'],\n",
        "    'Quantity': 'sum',\n",
        "    'Product': 'nunique'\n",
        "}).round(2)\n",
        "\n",
        "customer_stats.columns = ['Total_Sales', 'Avg_Sales', 'Transaction_Count', 'Total_Quantity', 'Unique_Products']\n",
        "\n",
        "# Create customer segments\n",
        "customer_stats['Customer_Segment'] = pd.cut(customer_stats['Total_Sales'], \n",
        "                                           bins=[0, 1000, 5000, 10000, float('inf')],\n",
        "                                           labels=['Low Value', 'Medium Value', 'High Value', 'VIP'])\n",
        "\n",
        "segment_analysis = customer_stats.groupby('Customer_Segment').agg({\n",
        "    'Total_Sales': ['count', 'sum', 'mean'],\n",
        "    'Transaction_Count': 'mean',\n",
        "    'Unique_Products': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "segment_analysis.columns = ['Customer_Count', 'Total_Sales', 'Avg_Sales', 'Avg_Transactions', 'Avg_Unique_Products']\n",
        "\n",
        "print(\"\\nüìä CUSTOMER SEGMENTATION:\")\n",
        "print(\"-\" * 30)\n",
        "print(segment_analysis)\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Customer segment distribution\n",
        "segment_counts = customer_stats['Customer_Segment'].value_counts()\n",
        "axes[0].pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%',\n",
        "            colors=['lightcoral', 'lightblue', 'lightgreen', 'gold'])\n",
        "axes[0].set_title('Customer Segment Distribution')\n",
        "\n",
        "# Average sales by segment\n",
        "segment_avg_sales = customer_stats.groupby('Customer_Segment')['Total_Sales'].mean()\n",
        "axes[1].bar(range(len(segment_avg_sales)), segment_avg_sales.values, \n",
        "            color=['lightcoral', 'lightblue', 'lightgreen', 'gold'])\n",
        "axes[1].set_title('Average Sales by Customer Segment')\n",
        "axes[1].set_xlabel('Customer Segment')\n",
        "axes[1].set_ylabel('Average Sales ($)')\n",
        "axes[1].set_xticks(range(len(segment_avg_sales)))\n",
        "axes[1].set_xticklabels(segment_avg_sales.index)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 9: Insights & Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T·ªïng h·ª£p Insights v√† Conclusions\n",
        "print(\"üéØ SALES DATASET EDA - INSIGHTS & CONCLUSIONS\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "print(\"\\nüìä KEY FINDINGS:\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# 1. Dataset Overview\n",
        "print(\"1. DATASET OVERVIEW:\")\n",
        "print(f\"   ‚Ä¢ Total transactions: {len(df):,}\")\n",
        "print(f\"   ‚Ä¢ Total revenue: ${df['Sales'].sum():,.2f}\")\n",
        "print(f\"   ‚Ä¢ Date range: {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
        "print(f\"   ‚Ä¢ Unique customers: {df['Customer_ID'].nunique():,}\")\n",
        "print(f\"   ‚Ä¢ Products: {df['Product'].nunique()}\")\n",
        "print(f\"   ‚Ä¢ Categories: {df['Category'].nunique()}\")\n",
        "print(f\"   ‚Ä¢ Regions: {df['Region'].nunique()}\")\n",
        "\n",
        "# 2. Sales Performance\n",
        "print(\"\\n2. SALES PERFORMANCE:\")\n",
        "best_product = df.groupby('Product')['Sales'].sum().idxmax()\n",
        "best_category = df.groupby('Category')['Sales'].sum().idxmax()\n",
        "best_region = df.groupby('Region')['Sales'].sum().idxmax()\n",
        "best_month = df.groupby('Month')['Sales'].mean().idxmax()\n",
        "\n",
        "print(f\"   ‚Ä¢ Best performing product: {best_product}\")\n",
        "print(f\"   ‚Ä¢ Best performing category: {best_category}\")\n",
        "print(f\"   ‚Ä¢ Best performing region: {best_region}\")\n",
        "print(f\"   ‚Ä¢ Best performing month: {month_names[best_month-1]}\")\n",
        "\n",
        "# 3. Customer Insights\n",
        "print(\"\\n3. CUSTOMER INSIGHTS:\")\n",
        "avg_transaction_value = df['Sales'].mean()\n",
        "avg_customer_value = df.groupby('Customer_ID')['Sales'].sum().mean()\n",
        "repeat_customers = (df.groupby('Customer_ID').size() > 1).sum()\n",
        "\n",
        "print(f\"   ‚Ä¢ Average transaction value: ${avg_transaction_value:.2f}\")\n",
        "print(f\"   ‚Ä¢ Average customer lifetime value: ${avg_customer_value:.2f}\")\n",
        "print(f\"   ‚Ä¢ Repeat customers: {repeat_customers:,} ({repeat_customers/df['Customer_ID'].nunique()*100:.1f}%)\")\n",
        "\n",
        "# 4. Seasonal Patterns\n",
        "print(\"\\n4. SEASONAL PATTERNS:\")\n",
        "monthly_variance = df.groupby('Month')['Sales'].mean().std()\n",
        "weekday_variance = df.groupby('Weekday')['Sales'].mean().std()\n",
        "\n",
        "print(f\"   ‚Ä¢ Monthly sales variation: ${monthly_variance:.2f}\")\n",
        "print(f\"   ‚Ä¢ Weekday sales variation: ${weekday_variance:.2f}\")\n",
        "print(f\"   ‚Ä¢ Peak season: {month_names[df.groupby('Month')['Sales'].sum().idxmax()-1]}\")\n",
        "print(f\"   ‚Ä¢ Busiest day: {weekday_names[df.groupby('Weekday')['Sales'].sum().idxmax()]}\")\n",
        "\n",
        "# 5. Business Recommendations\n",
        "print(\"\\n5. BUSINESS RECOMMENDATIONS:\")\n",
        "print(\"   ‚Ä¢ Focus marketing efforts on Electronics category (highest revenue)\")\n",
        "print(\"   ‚Ä¢ Expand operations in best-performing regions\")\n",
        "print(\"   ‚Ä¢ Develop seasonal strategies for peak months\")\n",
        "print(\"   ‚Ä¢ Implement customer retention programs for repeat buyers\")\n",
        "print(\"   ‚Ä¢ Consider pricing strategies for high-value products\")\n",
        "\n",
        "# 6. Data Quality\n",
        "print(\"\\n6. DATA QUALITY:\")\n",
        "print(\"   ‚Ä¢ No missing values detected\")\n",
        "print(\"   ‚Ä¢ No duplicate transactions found\")\n",
        "print(\"   ‚Ä¢ Data covers complete 2-year period\")\n",
        "print(\"   ‚Ä¢ All transactions have valid customer IDs\")\n",
        "print(\"   ‚Ä¢ Price and quantity data is consistent\")\n",
        "\n",
        "print(\"\\n‚úÖ EDA COMPLETED SUCCESSFULLY!\")\n",
        "print(\"üìà Ready for advanced analytics and machine learning models!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Next Steps\n",
        "\n",
        "Sau khi ho√†n th√†nh EDA cho Sales Dataset, b·∫°n c√≥ th·ªÉ:\n",
        "\n",
        "### üìà Advanced Analytics\n",
        "- **Time Series Forecasting**: D·ª± ƒëo√°n doanh thu trong t∆∞∆°ng lai\n",
        "- **Customer Lifetime Value**: T√≠nh to√°n CLV cho t·ª´ng kh√°ch h√†ng\n",
        "- **Market Basket Analysis**: Ph√¢n t√≠ch gi·ªè h√†ng v√† cross-selling\n",
        "- **Churn Prediction**: D·ª± ƒëo√°n kh√°ch h√†ng c√≥ th·ªÉ r·ªùi b·ªè\n",
        "\n",
        "### ü§ñ Machine Learning Models\n",
        "- **Sales Prediction Model**: D·ª± ƒëo√°n doanh thu theo th·ªùi gian\n",
        "- **Customer Segmentation**: Ph√¢n nh√≥m kh√°ch h√†ng b·∫±ng clustering\n",
        "- **Price Optimization**: T·ªëi ∆∞u h√≥a gi√° s·∫£n ph·∫©m\n",
        "- **Demand Forecasting**: D·ª± b√°o nhu c·∫ßu s·∫£n ph·∫©m\n",
        "\n",
        "### üìä Business Intelligence\n",
        "- **Dashboard Creation**: T·∫°o dashboard real-time\n",
        "- **KPI Monitoring**: Theo d√µi c√°c ch·ªâ s·ªë kinh doanh\n",
        "- **A/B Testing**: Th·ª≠ nghi·ªám c√°c chi·∫øn l∆∞·ª£c marketing\n",
        "- **ROI Analysis**: Ph√¢n t√≠ch hi·ªáu qu·∫£ ƒë·∫ßu t∆∞\n",
        "\n",
        "### üîÑ Data Pipeline\n",
        "- **Automated EDA**: T·ª± ƒë·ªông h√≥a qu√° tr√¨nh EDA\n",
        "- **Data Validation**: Ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu\n",
        "- **Real-time Processing**: X·ª≠ l√Ω d·ªØ li·ªáu real-time\n",
        "- **Data Warehousing**: L∆∞u tr·ªØ v√† qu·∫£n l√Ω d·ªØ li·ªáu\n",
        "\n",
        "---\n",
        "\n",
        "**üéâ Ch√∫c m·ª´ng! B·∫°n ƒë√£ ho√†n th√†nh EDA cho Sales Dataset!**\n",
        "\n",
        "*H√£y ti·∫øp t·ª•c v·ªõi dataset ti·∫øp theo ho·∫∑c √°p d·ª•ng insights n√†y v√†o c√°c d·ª± √°n th·ª±c t·∫ø!*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PoC-ML-Credit-Scoring",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
