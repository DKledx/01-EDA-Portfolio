{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä Sales Dataset EDA - Ph√¢n T√≠ch D·ªØ Li·ªáu B√°n H√†ng\n",
        "\n",
        "## üéØ M·ª•c Ti√™u\n",
        "Ph√¢n t√≠ch kh√°m ph√° d·ªØ li·ªáu b√°n h√†ng ƒë·ªÉ hi·ªÉu:\n",
        "- Xu h∆∞·ªõng b√°n h√†ng theo th·ªùi gian\n",
        "- Ph√¢n t√≠ch theo s·∫£n ph·∫©m, khu v·ª±c, kh√°ch h√†ng\n",
        "- Seasonal patterns v√† trends\n",
        "- Customer behavior analysis\n",
        "\n",
        "## üìã Dataset Overview\n",
        "- **Ngu·ªìn**: Synthetic Sales Data\n",
        "- **Th·ªùi gian**: 2 nƒÉm (2022-2023)\n",
        "- **Features**: Date, Product, Category, Region, Customer, Sales, Quantity, Price\n",
        "- **M·ª•c ti√™u**: Time series analysis, seasonal patterns, customer segmentation\n",
        "\n",
        "## üîç K·ªπ Thu·∫≠t S·∫Ω S·ª≠ D·ª•ng\n",
        "- Time series analysis\n",
        "- Seasonal decomposition\n",
        "- Customer segmentation\n",
        "- Product performance analysis\n",
        "- Geographic analysis\n",
        "- Trend analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# C√†i ƒë·∫∑t style cho plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ ƒê√£ import th√†nh c√¥ng t·∫•t c·∫£ th∆∞ vi·ªán!\")\n",
        "print(\"üìä S·∫µn s√†ng b·∫Øt ƒë·∫ßu ph√¢n t√≠ch Sales Dataset!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 1: T·∫°o Synthetic Sales Dataset\n",
        "\n",
        "T·∫°o dataset b√°n h√†ng t·ªïng h·ª£p v·ªõi c√°c ƒë·∫∑c ƒëi·ªÉm th·ª±c t·∫ø:\n",
        "- D·ªØ li·ªáu 2 nƒÉm (2022-2023)\n",
        "- 5 s·∫£n ph·∫©m ch√≠nh v·ªõi 3 categories\n",
        "- 4 khu v·ª±c b√°n h√†ng\n",
        "- 1000+ kh√°ch h√†ng\n",
        "- Seasonal patterns v√† trends\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T·∫°o synthetic sales dataset\n",
        "np.random.seed(42)\n",
        "\n",
        "# Th√¥ng tin c∆° b·∫£n\n",
        "start_date = '2022-01-01'\n",
        "end_date = '2023-12-31'\n",
        "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "\n",
        "# S·∫£n ph·∫©m v√† categories\n",
        "products = {\n",
        "    'Laptop Gaming': 'Electronics',\n",
        "    'iPhone 14': 'Electronics', \n",
        "    'Nike Air Max': 'Fashion',\n",
        "    'Adidas Ultraboost': 'Fashion',\n",
        "    'MacBook Pro': 'Electronics',\n",
        "    'Samsung Galaxy': 'Electronics',\n",
        "    'Levi\\'s Jeans': 'Fashion',\n",
        "    'Zara Jacket': 'Fashion',\n",
        "    'iPad Air': 'Electronics',\n",
        "    'Nike T-Shirt': 'Fashion'\n",
        "}\n",
        "\n",
        "# Khu v·ª±c\n",
        "regions = ['North', 'South', 'East', 'West']\n",
        "\n",
        "# T·∫°o d·ªØ li·ªáu\n",
        "sales_data = []\n",
        "\n",
        "for date in date_range:\n",
        "    # S·ªë l∆∞·ª£ng giao d·ªãch trong ng√†y (c√≥ seasonal pattern)\n",
        "    day_of_year = date.timetuple().tm_yday\n",
        "    seasonal_factor = 1 + 0.3 * np.sin(2 * np.pi * day_of_year / 365)  # Seasonal pattern\n",
        "    weekend_factor = 0.7 if date.weekday() >= 5 else 1.0  # Weekend effect\n",
        "    holiday_factor = 1.5 if date.month in [11, 12] else 1.0  # Holiday season\n",
        "    \n",
        "    num_transactions = int(np.random.poisson(50 * seasonal_factor * weekend_factor * holiday_factor))\n",
        "    \n",
        "    for _ in range(num_transactions):\n",
        "        product = np.random.choice(list(products.keys()))\n",
        "        category = products[product]\n",
        "        region = np.random.choice(regions)\n",
        "        customer_id = f\"CUST_{np.random.randint(1000, 9999)}\"\n",
        "        \n",
        "        # Gi√° s·∫£n ph·∫©m (c√≥ variation theo th·ªùi gian)\n",
        "        base_prices = {\n",
        "            'Laptop Gaming': 1200, 'iPhone 14': 800, 'Nike Air Max': 120,\n",
        "            'Adidas Ultraboost': 150, 'MacBook Pro': 2000, 'Samsung Galaxy': 600,\n",
        "            'Levi\\'s Jeans': 80, 'Zara Jacket': 120, 'iPad Air': 500, 'Nike T-Shirt': 30\n",
        "        }\n",
        "        \n",
        "        base_price = base_prices[product]\n",
        "        price_variation = np.random.normal(1, 0.1)  # 10% variation\n",
        "        price = base_price * price_variation\n",
        "        \n",
        "        # S·ªë l∆∞·ª£ng (th∆∞·ªùng 1-3 items)\n",
        "        quantity = np.random.choice([1, 2, 3], p=[0.7, 0.2, 0.1])\n",
        "        \n",
        "        # Total sales\n",
        "        sales = price * quantity\n",
        "        \n",
        "        # Discount factor (10% chance of discount)\n",
        "        if np.random.random() < 0.1:\n",
        "            discount = np.random.uniform(0.05, 0.25)\n",
        "            sales *= (1 - discount)\n",
        "        \n",
        "        sales_data.append({\n",
        "            'Date': date,\n",
        "            'Product': product,\n",
        "            'Category': category,\n",
        "            'Region': region,\n",
        "            'Customer_ID': customer_id,\n",
        "            'Price': round(price, 2),\n",
        "            'Quantity': quantity,\n",
        "            'Sales': round(sales, 2),\n",
        "            'Year': date.year,\n",
        "            'Month': date.month,\n",
        "            'Day': date.day,\n",
        "            'Weekday': date.weekday(),\n",
        "            'Quarter': date.quarter\n",
        "        })\n",
        "\n",
        "# T·∫°o DataFrame\n",
        "df = pd.DataFrame(sales_data)\n",
        "\n",
        "print(f\"‚úÖ ƒê√£ t·∫°o th√†nh c√¥ng Sales Dataset!\")\n",
        "print(f\"üìä K√≠ch th∆∞·ªõc dataset: {df.shape}\")\n",
        "print(f\"üìÖ Th·ªùi gian: {df['Date'].min()} ƒë·∫øn {df['Date'].max()}\")\n",
        "print(f\"üí∞ T·ªïng doanh thu: ${df['Sales'].sum():,.2f}\")\n",
        "print(f\"üõçÔ∏è T·ªïng s·ªë giao d·ªãch: {len(df):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 2: Data Loading & Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ki·ªÉm tra th√¥ng tin c∆° b·∫£n v·ªÅ dataset\n",
        "print(\"üîç TH√îNG TIN C∆† B·∫¢N V·ªÄ DATASET\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìä Shape: {df.shape}\")\n",
        "print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(f\"üìÖ Date range: {df['Date'].min()} ƒë·∫øn {df['Date'].max()}\")\n",
        "print(f\"üìà Total days: {(df['Date'].max() - df['Date'].min()).days + 1}\")\n",
        "\n",
        "print(\"\\nüìã COLUMNS INFO:\")\n",
        "print(\"=\" * 30)\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nüî¢ DATA TYPES:\")\n",
        "print(\"=\" * 20)\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nüìä SAMPLE DATA (5 rows ƒë·∫ßu):\")\n",
        "print(\"=\" * 35)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ki·ªÉm tra missing values\n",
        "print(\"üîç MISSING VALUES ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percent = (missing_data / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_data,\n",
        "    'Missing Percentage': missing_percent\n",
        "})\n",
        "\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "if missing_df['Missing Count'].sum() == 0:\n",
        "    print(\"‚úÖ Kh√¥ng c√≥ missing values trong dataset!\")\n",
        "\n",
        "# Ki·ªÉm tra duplicate rows\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"\\nüîÑ Duplicate rows: {duplicates}\")\n",
        "\n",
        "# Ki·ªÉm tra unique values cho categorical columns\n",
        "print(\"\\nüìä UNIQUE VALUES:\")\n",
        "print(\"=\" * 25)\n",
        "categorical_cols = ['Product', 'Category', 'Region', 'Customer_ID']\n",
        "for col in categorical_cols:\n",
        "    unique_count = df[col].nunique()\n",
        "    print(f\"{col}: {unique_count} unique values\")\n",
        "    \n",
        "    if col in ['Product', 'Category', 'Region']:\n",
        "        print(f\"  Values: {list(df[col].unique())}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 3: Data Profiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary cho numerical columns\n",
        "print(\"üìä STATISTICAL SUMMARY\")\n",
        "print(\"=\" * 30)\n",
        "numerical_cols = ['Price', 'Quantity', 'Sales']\n",
        "print(df[numerical_cols].describe().round(2))\n",
        "\n",
        "# Th√™m m·ªôt s·ªë th·ªëng k√™ b·ªï sung\n",
        "print(\"\\nüìà ADDITIONAL STATISTICS\")\n",
        "print(\"=\" * 35)\n",
        "for col in numerical_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Mean: ${df[col].mean():.2f}\")\n",
        "    print(f\"  Median: ${df[col].median():.2f}\")\n",
        "    print(f\"  Std: ${df[col].std():.2f}\")\n",
        "    print(f\"  Min: ${df[col].min():.2f}\")\n",
        "    print(f\"  Max: ${df[col].max():.2f}\")\n",
        "    print(f\"  Skewness: {df[col].skew():.3f}\")\n",
        "    print(f\"  Kurtosis: {df[col].kurtosis():.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ph√¢n t√≠ch categorical features\n",
        "print(\"üìä CATEGORICAL FEATURES ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Product analysis\n",
        "print(\"\\nüõçÔ∏è PRODUCT ANALYSIS:\")\n",
        "print(\"-\" * 25)\n",
        "product_stats = df.groupby('Product').agg({\n",
        "    'Sales': ['count', 'sum', 'mean'],\n",
        "    'Quantity': 'sum',\n",
        "    'Price': 'mean'\n",
        "}).round(2)\n",
        "product_stats.columns = ['Transactions', 'Total_Sales', 'Avg_Sales', 'Total_Quantity', 'Avg_Price']\n",
        "product_stats = product_stats.sort_values('Total_Sales', ascending=False)\n",
        "print(product_stats)\n",
        "\n",
        "# Category analysis\n",
        "print(\"\\nüìÇ CATEGORY ANALYSIS:\")\n",
        "print(\"-\" * 25)\n",
        "category_stats = df.groupby('Category').agg({\n",
        "    'Sales': ['count', 'sum', 'mean'],\n",
        "    'Quantity': 'sum',\n",
        "    'Price': 'mean'\n",
        "}).round(2)\n",
        "category_stats.columns = ['Transactions', 'Total_Sales', 'Avg_Sales', 'Total_Quantity', 'Avg_Price']\n",
        "category_stats = category_stats.sort_values('Total_Sales', ascending=False)\n",
        "print(category_stats)\n",
        "\n",
        "# Region analysis\n",
        "print(\"\\nüåç REGION ANALYSIS:\")\n",
        "print(\"-\" * 20)\n",
        "region_stats = df.groupby('Region').agg({\n",
        "    'Sales': ['count', 'sum', 'mean'],\n",
        "    'Quantity': 'sum',\n",
        "    'Price': 'mean'\n",
        "}).round(2)\n",
        "region_stats.columns = ['Transactions', 'Total_Sales', 'Avg_Sales', 'Total_Quantity', 'Avg_Price']\n",
        "region_stats = region_stats.sort_values('Total_Sales', ascending=False)\n",
        "print(region_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä B∆∞·ªõc 4: Missing Value Analysis\n",
        "\n",
        "V√¨ dataset n√†y l√† synthetic data n√™n kh√¥ng c√≥ missing values, nh∆∞ng ch√∫ng ta s·∫Ω ki·ªÉm tra v√† t·∫°o visualization ƒë·ªÉ hi·ªÉu pattern.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing value visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Missing value heatmap\n",
        "missing_data = df.isnull().sum()\n",
        "if missing_data.sum() > 0:\n",
        "    sns.heatmap(df.isnull(), yticklabels=False, cbar=True, cmap='viridis', ax=axes[0])\n",
        "    axes[0].set_title('Missing Values Heatmap')\n",
        "else:\n",
        "    axes[0].text(0.5, 0.5, '‚úÖ No Missing Values', ha='center', va='center', \n",
        "                transform=axes[0].transAxes, fontsize=16, color='green')\n",
        "    axes[0].set_title('Missing Values Status')\n",
        "\n",
        "# Data completeness\n",
        "completeness = (1 - missing_data / len(df)) * 100\n",
        "bars = axes[1].bar(range(len(completeness)), completeness.values, color='lightgreen')\n",
        "axes[1].set_title('Data Completeness by Column')\n",
        "axes[1].set_xlabel('Columns')\n",
        "axes[1].set_ylabel('Completeness (%)')\n",
        "axes[1].set_xticks(range(len(completeness)))\n",
        "axes[1].set_xticklabels(completeness.index, rotation=45)\n",
        "axes[1].set_ylim(0, 105)\n",
        "\n",
        "# Add percentage labels on bars\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                f'{height:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Dataset ho√†n to√†n clean - kh√¥ng c√≥ missing values!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
